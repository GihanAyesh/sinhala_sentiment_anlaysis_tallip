{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of second cnn_rnn_multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xXiAlHRZ7X_p",
        "Zk1Up-Co0r3t",
        "hwtwg7MaUg_7",
        "IHqkf0XG8dqL",
        "sPm_9b6Y8EPi",
        "B6CXqtIDR4jS",
        "H-RSSqI7BDqE",
        "KMtXKRpRYBx2",
        "BtZBU5XNZaMi",
        "LR7WojLAszo7"
      ]
    },
    "environment": {
      "name": "tf2-2-2-gpu.2-2.m50",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zR8-aK009p9"
      },
      "source": [
        "# User Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbSiWEihH0zu",
        "outputId": "2e55f86c-7aaa-4a5f-db6a-c6b7c6c3bb53"
      },
      "source": [
        "Host = \"colab\" #@param [\"colab\", \"AWS\", \"GCP\"]\n",
        "\n",
        "Account = \"colab_datapirates\" #@param[\"colab_datapirates\", \"colab_lahiru_cse\", \"colab_lahiru_personal\"]\n",
        "EMBEDDING_SIZE = 300 #@param [50, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "embedding_type = \"fasttext\" #@param [\"fasttext\",\"word2vec\"]\n",
        "experiment_no = \"2\" #@param [] {allow-input: true}\n",
        "model_type = \"BiLSTM\" #@param [\"RNN\",\"GRU\", \"LSTM\", \"BiLSTM\" ] \n",
        "\n",
        "stack_modeles = \"2\" #@param [\"\",\"2\",\"3\"]\n",
        "apply_CNN = False #@param {type:\"boolean\"}\n",
        "\n",
        "model_name = model_type + \"_model\"\n",
        "if(stack_modeles == \"2\" or stack_modeles == \"3\"):\n",
        "  model_name = \"stacked_\" + model_name + \"_\" + stack_modeles\n",
        "if(apply_CNN):\n",
        "  model_name = \"CNN_\" + model_name \n",
        "\n",
        "print(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stacked_BiLSTM_model_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7y2rE1vNZWc"
      },
      "source": [
        "# Folder Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDq--mTz9k24",
        "outputId": "f61d7d2c-a937-4d07-84f6-277c9ca6a129"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWPD3dgEqB5d"
      },
      "source": [
        "folder_path = '/content/drive/MyDrive/Sencat'\n",
        "\n",
        "EMBEDDING_SIZE = 300 \n",
        "embedding_type = \"fastText\"\n",
        "context = 5\n",
        "\n",
        "word_embedding_path = folder_path + \"/embedding/\"+ str(EMBEDDING_SIZE)+\"/\" + embedding_type+\"_\"+str(EMBEDDING_SIZE)+\"_\"+str(context)\n",
        "word_embedding_keydvectors_path = folder_path +\"/embedding/\"+str(EMBEDDING_SIZE)+\"/keyed_vectors/keyed.kv\"\n",
        "embedding_matrix_path = folder_path + '/embedding/'+embedding_type+'_lankadeepa_gossiplanka_'+str(EMBEDDING_SIZE)+'_'+str(context)\n",
        "\n",
        "experiment_name = folder_path + \"/CNN_RNN/\" +str(experiment_no) + \"_\"+ model_name +\"_\"+embedding_type+\"_\"+str(EMBEDDING_SIZE)+\"_\"+str(context)\n",
        "model_save_path = folder_path + \"/CNN_RNN/\"+str(experiment_no)+\"_weights_best_\"+model_name+\"_\"+embedding_type+\"_\"+str(experiment_no)+\".hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BYvE-D5QAc0"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf2gZocJff8x",
        "outputId": "c61cb6a5-2e15-4852-858e-f29a9a70ea7b"
      },
      "source": [
        "# import os, sys\n",
        "# nb_path = '/content/colabnotebooks'\n",
        "# # os.symlink('/content/drive/MyDrive/Colab Notebooks', nb_path)\n",
        "# sys.path.insert(0,nb_path)\n",
        "\n",
        "# !pip uninstall --target=$nb_path keras-nightly\n",
        "# !pip install --target=$nb_path tensorflow==1.14.0\n",
        "# !pip install --target=$nb_path q keras==2.3.1\n",
        "# !pip install --target=$nb_path 'h5py<3.0.0'\n",
        "\n",
        "!pip uninstall keras-nightly\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install q keras==2.3.1\n",
        "!pip install 'h5py<3.0.0'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras_nightly-2.5.0.dev2021032900.dist-info/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/applications/resnet50.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/network.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/topology.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/initializers.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/layers/experimental/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/layers/experimental/preprocessing/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/objectives.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/optimizers/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/optimizers/schedules/__init__.py\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/utils/test_utils.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 93kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.34.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.6.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting q\n",
            "  Downloading https://files.pythonhosted.org/packages/53/bc/51619d89e0bd855567e7652fa16d06f1ed36a85f108a7fe71f6629bf719d/q-2.6-py2.py3-none-any.whl\n",
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
            "Installing collected packages: q, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1 q-2.6\n",
            "Collecting h5py<3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ9YDtD6qn4t",
        "outputId": "85c42b7a-6b4a-4172-c15a-b9fa10a42ba0"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import pickle\n",
        "import re\n",
        "import random\n",
        "import sys\n",
        "import os \n",
        "import time\n",
        "\n",
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models import word2vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import cumsum\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dropout, Activation, Flatten, \\\n",
        "    Embedding, Convolution1D, MaxPooling1D, AveragePooling1D, \\\n",
        "    Input, Dense, merge, Add,TimeDistributed, Bidirectional,SpatialDropout1D\n",
        "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
        "from keras.regularizers import l2, l1_l2\n",
        "from keras.constraints import maxnorm\n",
        "from keras import callbacks\n",
        "from keras.utils import generic_utils,plot_model\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXiAlHRZ7X_p"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqqHP9rwpbdt",
        "outputId": "6b1e54bd-ac51-47fb-e3ab-3a7c5e808e75"
      },
      "source": [
        "# lankadeepa_data_path = folder_path + '/data/lankadeepa_tagged_comments.csv'\n",
        "# gossip_lanka_data_path = folder_path + '/data/gossip_lanka_tagged_comments.csv'\n",
        "# lankadeepa_data = pd.read_csv(lankadeepa_data_path)[:9059]\n",
        "# lankadeepa_data = lankadeepa_data[((lankadeepa_data['label']==2) | (lankadeepa_data['label']==4))]\n",
        "# all_data = pd.concat([lankadeepa_data], ignore_index=True)\n",
        "# all_data.info()\n",
        "\n",
        "facebook_data_path = folder_path + '/data/labeled_corpus.csv'\n",
        "all_data = pd.read_csv(facebook_data_path)\n",
        "all_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 381891 entries, 0 to 381890\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  381891 non-null  int64 \n",
            " 1   comment     381891 non-null  object\n",
            " 2   label       381891 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 8.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk1Up-Co0r3t"
      },
      "source": [
        "## Count Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS7TzP2tyhF6"
      },
      "source": [
        "# data_path = folder_path + \"corpus/new/preprocess_from_isuru/gossip_lanka_all_comments.csv\"\n",
        "# # \"corpus/new/preprocess_from_isuru/lankadeepa_comments_with_article_2.csv\"\n",
        "# data = pd.read_csv(data_path)\n",
        "\n",
        "# def count_tokens(pandas_df):\n",
        "\n",
        "#   count = 0\n",
        "#   for index, row in pandas_df.iterrows():\n",
        "#     comment_words,article_words = 0,0\n",
        "#     if (type(row['comment']) == str) :\n",
        "#       comment_words = len(row['comment'].split())\n",
        "#     # if (type(row['article']) == str) :\n",
        "#     #   article_words = len(row['article'].split())\n",
        "#     count += (comment_words + article_words)\n",
        "#   return count\n",
        "\n",
        "# tokens = count_tokens(data)\n",
        "# print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTRgXvPTbzi3"
      },
      "source": [
        "# all_data_path = folder_path + \n",
        "# \"corpus/new/tagged_comments_all_with_punctuation_marks.csv\" done\n",
        "# \"corpus/new/tagged_comments_all_with_punctuation_marks_question_only.csv\"\n",
        "# corpus/new/tagged_comments_all_without_punctuation_marks.csv\n",
        "\n",
        "# all_data = pd.read_csv(all_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwtwg7MaUg_7"
      },
      "source": [
        "## Some other Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GJxgz7TyXP"
      },
      "source": [
        "# all_data['comment'] = all_data['comment'].str.replace('?', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCCrt693RmRT"
      },
      "source": [
        "# all_data.to_csv(folder_path + 'corpus/new/tagged_comments_all_without_punctuation_marks.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxm16KdZVIWo"
      },
      "source": [
        "# all_data['label'].value_counts()\n",
        "# set(lankadeepa_data.comment.apply(list).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shq4w6GcqbIq"
      },
      "source": [
        "# Create Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHqkf0XG8dqL"
      },
      "source": [
        "## comment-label split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ynks11qZ-e"
      },
      "source": [
        "# edit this later \n",
        "def text_preprocessing(train_data,test_data):\n",
        "  train_data_texts = train_data['comment']\n",
        "  train_data_labels = train_data['label']\n",
        "  test_data_texts = test_data['comment']\n",
        "  test_data_labels = test_data['label']\n",
        "\n",
        "\n",
        "  comment_texts = []\n",
        "  comment_labels = []\n",
        "\n",
        "  train_text = []\n",
        "  test_text = []\n",
        "  train_labels=[]\n",
        "  test_labels=[]\n",
        "\n",
        "  for label in train_data_labels:\n",
        "    if label == \"POSITIVE\":\n",
        "      train_labels.append(1)\n",
        "    else:\n",
        "      train_labels.append(0)\n",
        "  comment_labels.append(train_labels)\n",
        "\n",
        "  for label in test_data_labels:\n",
        "    if label == \"POSITIVE\":\n",
        "      test_labels.append(1)\n",
        "    else:\n",
        "      test_labels.append(0)\n",
        "  comment_labels.append(test_labels)\n",
        "  \n",
        "\n",
        "  for comment in train_data_texts:\n",
        "    lines = []\n",
        "    try:\n",
        "      words = comment.split()\n",
        "      lines += words\n",
        "    except:\n",
        "      continue\n",
        "    train_text.append(lines)\n",
        "  comment_texts.append(train_text)\n",
        "\n",
        "  for comment in test_data_texts:\n",
        "    lines = []\n",
        "    try:\n",
        "      words = comment.split()\n",
        "      lines += words\n",
        "    except:\n",
        "      continue\n",
        "    test_text.append(lines)\n",
        "  comment_texts.append(test_text)\n",
        "\n",
        "\n",
        "  return comment_texts,comment_labels\n",
        "\n",
        "# edit this later \n",
        "def text_preprocessing_1(data):\n",
        "  comments = data['comment']\n",
        "  labels = data['label']\n",
        "\n",
        "  comments_splitted = []\n",
        "  labels_encoded = []\n",
        "\n",
        "  for label in labels:\n",
        "    if label == \"POSITIVE\":\n",
        "      labels_encoded.append(1)\n",
        "    else:\n",
        "      labels_encoded.append(0)\n",
        "\n",
        "  for comment in comments:\n",
        "    lines = []\n",
        "    try:\n",
        "      words = comment.split()\n",
        "      lines += words\n",
        "    except:\n",
        "      continue\n",
        "    comments_splitted.append(lines)\n",
        "  return comments_splitted,labels_encoded\n",
        "\n",
        "\n",
        "def text_preprocessing_2(data):\n",
        "  comments = data['comment']\n",
        "  labels = data['label']\n",
        "\n",
        "  comments_splitted = []\n",
        "\n",
        "  for comment in comments:\n",
        "    lines = []\n",
        "    try:\n",
        "      words = comment.split()\n",
        "      lines += words\n",
        "    except:\n",
        "      continue\n",
        "    comments_splitted.append(lines)\n",
        "\n",
        "  return comments_splitted,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdKgzrbd8Uy8"
      },
      "source": [
        "## Takenize and Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZoOqtodrUY1",
        "outputId": "b2e15d96-e9c1-4882-d8ef-92c337db9992"
      },
      "source": [
        "comment_texts, comment_labels = text_preprocessing_2(all_data)\n",
        "\n",
        "# prepare tokenizer\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(comment_texts)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMhZbzGur4kt"
      },
      "source": [
        "encoded_docs = t.texts_to_sequences(comment_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho5NTzHtsKoN"
      },
      "source": [
        "max_length = len(max(encoded_docs, key=len))\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length)\n",
        "\n",
        "comment_labels = np.array(comment_labels)\n",
        "padded_docs = np.array(padded_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBRINFtdvEQS",
        "outputId": "b8341569-798f-4ee8-9bd2-92a874fab719"
      },
      "source": [
        "comment_labels = pd.get_dummies(comment_labels).values\n",
        "print('Shape of label tensor:', comment_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (381891, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drgv_J0ZUV8j"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_docs, comment_labels, test_size=0.1, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49a_GcIvkmch",
        "outputId": "009ae6c0-4005-45dc-a465-437b6aca61ff"
      },
      "source": [
        "(unique, counts) = np.unique(y_test, return_counts = True)\n",
        "frequencies = np.asarray((unique, counts)).T\n",
        "print(frequencies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0 38190]\n",
            " [    1 38190]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91fqgdk67oaZ"
      },
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPm_9b6Y8EPi"
      },
      "source": [
        "## Generate Embedding Metrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOB0YKL-fNW5"
      },
      "source": [
        "def generate_embedding_metrix():\n",
        "  if (embedding_type == 'fasttext'):\n",
        "    word_embedding_model = FastText.load(word_embedding_path)\n",
        "  else:\n",
        "    word_embedding_model = word2vec.Word2Vec.load(word_embedding_path)\n",
        "    \n",
        "  word_vectors = word_embedding_model.wv\n",
        "  word_vectors.save(word_embedding_keydvectors_path)\n",
        "  word_vectors = KeyedVectors.load(word_embedding_keydvectors_path, mmap='r')\n",
        "\n",
        "  embeddings_index = dict()\n",
        "  for word, vocab_obj in word_vectors.vocab.items():\n",
        "    embeddings_index[word]=word_vectors[word]\n",
        "\n",
        "  # create a weight matrix for words in training docs\n",
        "  embedding_matrix = zeros((vocab_size, embedding_size))\n",
        "  for word, i in t.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  pickle.dump(embedding_matrix, open(embedding_matrix_path, 'wb'))\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVYEOwiN8H3s"
      },
      "source": [
        "## Load Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNSwoRM292-u"
      },
      "source": [
        "def load_word_embedding_atrix():\n",
        "  f = open(embedding_matrix_path, 'rb')\n",
        "  embedding_matrix= np.array(pickle.load(f))\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrmGuYXf82E_"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx80tScO_ddi"
      },
      "source": [
        "## RNN(LSTM/GRU) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9elMDrR_laX"
      },
      "source": [
        "def RNN_model(RNN_layer, maxlen, hidden_dims, l2_reg, drop_out_value_1, drop_out_value_2):\n",
        "    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n",
        "    embedding  = Embedding(MAX_FEATURES, EMBEDDING_SIZE,\n",
        "                  weights=[EMBEDDING_MATRIX], input_length=maxlen,\n",
        "                  name='embedding' ,trainable=False)(main_input)\n",
        "\n",
        "    embedding = Dropout(drop_out_value_1)(embedding)\n",
        "\n",
        "    x = RNN(hidden_dims)(embedding)\n",
        "\n",
        "    x = Dense(hidden_dims, activation='relu', init='he_normal', \n",
        "              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n",
        "              name='mlp')(x)\n",
        "\n",
        "    x = Dropout(drop_out_value_2, name='drop')(x)\n",
        "\n",
        "    output = Dense(2, init='he_normal',\n",
        "                   activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(input=main_input, output=output ,name=\"RNN_model\")\n",
        "\n",
        "    model.compile(loss={'output':'categorical_crossentropy'},\n",
        "              optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n",
        "              metrics=[\"accuracy\",\n",
        "                       tf.keras.metrics.Precision(),\n",
        "                        tf.keras.metrics.Recall(),\n",
        "                       f1])\n",
        "    \n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def stacked_RNN_model_2(RNN_layer, maxlen, hidden_dims, l2_reg, drop_out_value_1, drop_out_value_2):\n",
        "    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n",
        "    embedding  = Embedding(MAX_FEATURES, EMBEDDING_SIZE,\n",
        "                  weights=[EMBEDDING_MATRIX], input_length=maxlen,\n",
        "                  name='embedding' ,trainable=False)(main_input)\n",
        "\n",
        "    embedding = Dropout(drop_out_value_1)(embedding)\n",
        "\n",
        "    x = RNN_layer(hidden_dims,return_sequences=True)(embedding)\n",
        "    x = RNN_layer(hidden_dims)(x)\n",
        "\n",
        "    x = Dense(hidden_dims, activation='relu', init='he_normal',\n",
        "              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n",
        "              name='mlp')(x)\n",
        "\n",
        "    x = Dropout(drop_out_value_2, name='drop')(x)\n",
        "\n",
        "    output = Dense(2, init='he_normal',\n",
        "                   activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(input=main_input, output=output, name= \"stacked_RNN_model_2\")\n",
        "\n",
        "    model.compile(loss={'output':'categorical_crossentropy'},\n",
        "          optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n",
        "          metrics=[\"accuracy\",\n",
        "                       tf.keras.metrics.Precision(),\n",
        "                        tf.keras.metrics.Recall(),\n",
        "                       f1])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def stacked_RNN_model_3(RNN_layer, maxlen, hidden_dims, l2_reg, drop_out_value_1, drop_out_value_2):\n",
        "    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n",
        "    embedding  = Embedding(MAX_FEATURES, EMBEDDING_SIZE,\n",
        "                  weights=[EMBEDDING_MATRIX], input_length=maxlen,\n",
        "                  name='embedding' ,trainable=False)(main_input)\n",
        "\n",
        "    embedding = Dropout(drop_out_value_1)(embedding)\n",
        "\n",
        "    x = RNN_layer(hidden_dims,return_sequences=True)(embedding)\n",
        "    x = RNN_layer(hidden_dims,return_sequences=True)(x)\n",
        "    x = RNN_layer(hidden_dims)(x)\n",
        "\n",
        "    x = Dense(hidden_dims, activation='relu', init='he_normal',\n",
        "              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n",
        "              name='mlp')(x)\n",
        "\n",
        "    x = Dropout(drop_out_value_2, name='drop')(x)\n",
        "\n",
        "    output = Dense(2, init='he_normal',\n",
        "                   activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(input=main_input, output=output, name=\"stacked_RNN_model_3\")\n",
        "\n",
        "    model.compile(loss={'output':'categorical_crossentropy'},\n",
        "      optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n",
        "      metrics=[\"accuracy\",\n",
        "                    tf.keras.metrics.Precision(),\n",
        "                    tf.keras.metrics.Recall(),\n",
        "                    f1])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt3TZsP84gRK"
      },
      "source": [
        "## CNN+RNN(LSTM /GRU) model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3v2boPz4frA"
      },
      "source": [
        "def CNN_RNN_model(RNN_layer, maxlen, hidden_dims, l2_reg, drop_out_value_1, drop_out_value_2):\n",
        "    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n",
        "    embedding  = Embedding(MAX_FEATURES, EMBEDDING_SIZE,\n",
        "                  weights=[EMBEDDING_MATRIX], input_length=maxlen,\n",
        "                  name='embedding' ,trainable=False)(main_input)\n",
        "\n",
        "    embedding = Dropout(drop_out_value_1)(embedding)\n",
        "\n",
        "    conv4 = Convolution1D(NB_FILTERS,\n",
        "                          4,\n",
        "                          border_mode='valid',\n",
        "                          activation='relu',\n",
        "                          subsample_length=1,\n",
        "                          name='conv4')(embedding)\n",
        "    maxConv4 = MaxPooling1D(pool_length=2,\n",
        "                             name='maxConv4')(conv4)\n",
        "\n",
        "    conv5 = Convolution1D(NB_FILTERS,\n",
        "                          5,\n",
        "                          border_mode='valid',\n",
        "                          activation='relu',\n",
        "                          subsample_length=1,\n",
        "                          name='conv5')(embedding)\n",
        "    maxConv5 = MaxPooling1D(pool_length=2,\n",
        "                            name='maxConv5')(conv5)\n",
        "\n",
        "    x = keras.layers.Concatenate(axis=1)([maxConv4, maxConv5])\n",
        "\n",
        "    x = Dropout(drop_out_value_2)(x)\n",
        "\n",
        "    x = RNN(rnn_output_size)(x)\n",
        "\n",
        "\n",
        "    x = Dense(hidden_dims, activation='relu', init='he_normal',\n",
        "              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n",
        "              name='mlp')(x)\n",
        "\n",
        "    x = Dropout(drop_out_value_2, name='drop')(x)\n",
        "\n",
        "    output = Dense(2, init='he_normal',\n",
        "                   activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(input=main_input, output=output, name= \"CNN+RNN model\")\n",
        "\n",
        "    model.compile(loss={'output':'categorical_crossentropy'},\n",
        "      optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n",
        "      metrics=[\"accuracy\",\n",
        "                    tf.keras.metrics.Precision(),\n",
        "                    tf.keras.metrics.Recall(),\n",
        "                    f1])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxGsm-SlgL1q"
      },
      "source": [
        "## BiLSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeGG2DQWgQUK"
      },
      "source": [
        "# final model\n",
        "def BiLSTM_model(maxlen, drop_out_value):\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding(MAX_FEATURES,EMBEDDING_SIZE,weights=[EMBEDDING_MATRIX],input_length=maxlen)(input)\n",
        "\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n",
        "  model = TimeDistributed(Dense(300,activation='relu'))(model)\n",
        "  model = Flatten()(model)\n",
        "  # model = Dense(300,activation='relu')(model) # extra dense layer\n",
        "  output = Dense(2,activation='softmax')(model)\n",
        "  model = Model(input,output)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgoOdnHgZvZ"
      },
      "source": [
        "### Stacked_BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZgd_cbYgYc5"
      },
      "source": [
        "# final model\n",
        "def stacked_BiLSTM_model_2(maxlen, drop_out_value):\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding(MAX_FEATURES,EMBEDDING_SIZE,weights=[EMBEDDING_MATRIX],input_length=maxlen)(input)\n",
        "\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n",
        "  model = TimeDistributed(Dense(300,activation='relu'))(model)\n",
        "  model = Flatten()(model)\n",
        "  model = Dense(300,activation='relu')(model)\n",
        "  output = Dense(2,activation='softmax')(model)\n",
        "  model = Model(input,output)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=[\"accuracy\",\n",
        "                    tf.keras.metrics.Precision(),\n",
        "                    tf.keras.metrics.Recall(),\n",
        "                    f1])\n",
        "  return model\n",
        "\n",
        "# final model\n",
        "def stacked_BiLSTM_model_3(maxlen, drop_out_value):\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding(MAX_FEATURES,EMBEDDING_SIZE,weights=[EMBEDDING_MATRIX],input_length=maxlen)(input)\n",
        "\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n",
        "  model = TimeDistributed(Dense(300,activation='relu'))(model)\n",
        "  model = Flatten()(model)\n",
        "  model = Dense(300,activation='relu')(model)\n",
        "  output = Dense(2,activation='softmax')(model)\n",
        "  model = Model(input,output)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=[\"accuracy\",\n",
        "                    tf.keras.metrics.Precision(),\n",
        "                    tf.keras.metrics.Recall(),\n",
        "                    f1])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjRpo6igkE9"
      },
      "source": [
        "## CNN+BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM7tpzPEgjFh"
      },
      "source": [
        "def CNN_BiLSTM_model(maxlen):\n",
        "  # main model\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding(MAX_FEATURES,EMBEDDING_SIZE,weights=[EMBEDDING_MATRIX],input_length=maxlen)(input)\n",
        "\n",
        "  conv4 = Convolution1D(nb_filter=NB_FILTERS,\n",
        "                          filter_length=4,\n",
        "                          border_mode='valid',\n",
        "                          activation='relu',\n",
        "                          subsample_length=1,\n",
        "                          name='conv4')(embedding)\n",
        "  maxConv4 = MaxPooling1D(pool_length=2,\n",
        "                             name='maxConv4')(conv4)\n",
        "\n",
        "  conv5 = Convolution1D(nb_filter=NB_FILTERS,\n",
        "                          filter_length=5,\n",
        "                          border_mode='valid',\n",
        "                          activation='relu',\n",
        "                          subsample_length=1,\n",
        "                          name='conv5')(embedding)\n",
        "  maxConv5 = MaxPooling1D(pool_length=2,\n",
        "                            name='maxConv5')(conv5)\n",
        "\n",
        "\n",
        "  x = keras.layers.Concatenate(axis=1)([maxConv4, maxConv5])\n",
        "\n",
        "  x = Dropout(0.15)(x)\n",
        "\n",
        "  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=0.8),merge_mode='concat')(x)\n",
        "  model = TimeDistributed(Dense(300,activation='relu'))(model)\n",
        "  model = Flatten()(model)\n",
        "  model = Dense(300,activation='relu')(model)\n",
        "  output = Dense(2,activation='softmax')(model)\n",
        "  model = Model(input,output)\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=[\"accuracy\",\n",
        "                    tf.keras.metrics.Precision(),\n",
        "                    tf.keras.metrics.Recall(),\n",
        "                    f1])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC0ZRhKe5a6C"
      },
      "source": [
        "# Train and Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbpLZfOPGGKN"
      },
      "source": [
        "## Custom F1 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0sMLlLvEGKq"
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqK6yZoCHIyE"
      },
      "source": [
        "## Train and Validate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhOLwIC-5aiD"
      },
      "source": [
        "def Train_Model_old(model,X_train, X_test, y_train, y_test):\n",
        "\n",
        "  print('Training and Testing...')\n",
        "  test_accs = []\n",
        "  first_run = True\n",
        "\n",
        "\n",
        "  acc=[]\n",
        "  val_acc=[]\n",
        "  loss=[]\n",
        "  val_loss=[]\n",
        "  best_val_acc = 0\n",
        "  best_test_acc = 0\n",
        "  for j in range(nb_epoch):\n",
        "      a = time.time()\n",
        "      his = model.fit(X_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_data=[X_test, y_test],\n",
        "                      shuffle=True,\n",
        "                      epochs=1, verbose=verbosity)\n",
        "      acc+=his.history['accuracy']\n",
        "      val_acc+=his.history['val_accuracy']\n",
        "      loss+=his.history['loss']\n",
        "      val_loss+=his.history['val_loss']\n",
        "      # print('Epoch %d/%d\\t%s' % (j + 1, nb_epoch, str(his.history)))\n",
        "      if his.history['val_accuracy'][0] >= best_val_acc:\n",
        "          score, test_acc = model.evaluate(X_test, y_test,\n",
        "                                      batch_size=batch_size,\n",
        "                                      verbose=2)\n",
        "          best_val_acc = his.history['val_accuracy'][0]\n",
        "          best_test_acc = test_acc\n",
        "          print('Got best epoch  best val acc is %f test acc is %f' %\n",
        "                (best_val_acc, best_test_acc))\n",
        "          if len(test_accs) > 0:\n",
        "              print('Current avg test acc:', str(np.mean(test_accs)))\n",
        "      b = time.time()\n",
        "      cost = b - a\n",
        "      left = (nb_epoch - j - 1)\n",
        "      print('One round cost %ds, %d round %ds %dmin left' % (cost, left,\n",
        "                                                            cost * left,\n",
        "                                                            cost * left / 60.0))\n",
        "      test_accs.append(best_test_acc)\n",
        "\n",
        "  print('Avg test acc:', str(np.mean(test_accs)))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTuRxzncQc5q"
      },
      "source": [
        "def Train_Model(model,X_train, y_train, cross_validation = False):\n",
        "\n",
        "  print('Training and Testing...')\n",
        "  print (X_train.shape, y_train.shape)\n",
        "  \n",
        "  es = EarlyStopping(monitor='val_f1', mode='max', verbose=1, patience=5)\n",
        "  checkpoint = ModelCheckpoint(model_save_path, monitor='val_f1', verbose=1, save_weights_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint,es]\n",
        "\n",
        "  if (cross_validation):\n",
        "    callbacks_list = [es]\n",
        "\n",
        "  his = model.fit(X_train, y_train, validation_split=VALIDATION_SPLIT, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list, verbose=1)\n",
        "  \n",
        "\n",
        "  # checkpoint_path = folder_path + \"/CNN_RNN/\"+str(experiment_no)+\"_weights_best_\"+model_name+\"_\"+embedding_type+\"_\"+str(experiment_no)+\".ckpt\"\n",
        "  # checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # # Create a callback that saves the model's weights\n",
        "  # cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
        "\n",
        "  # # Train the model with the new callback\n",
        "  # his = model.fit(X_train, y_train, validation_split=VALIDATION_SPLIT, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, callbacks=[cp_callback])\n",
        "\n",
        "  return model,his"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4DuyDZMkcE3"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TMmqz8BkTQR"
      },
      "source": [
        "def Do_Cross_Validation(X,y):\n",
        "\n",
        "  # Define per-fold score containers\n",
        "  loss_per_fold = []\n",
        "  acc_per_fold = []\n",
        "  precision_per_fold = []\n",
        "  recall_per_fold = []\n",
        "  f1_per_fold = []\n",
        "  \n",
        "\n",
        "  kfold = KFold(n_splits=FOLDS, shuffle=True)\n",
        "\n",
        "  fold_no = 1\n",
        "  inputs = X\n",
        "  targets = y\n",
        "  for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "    # model = build_model()\n",
        "    model = RNN_model(GRU, MAX_LEN, HIDDEN_DIMS, L2_REG, DROPOUT_VALUE_1, DROPOUT_VALUE_2)\n",
        "    \n",
        "    # RNN_layer, maxlen, hidden_dims, l2_reg, drop_out_value_1, drop_out_value_2\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    model, his = Train_Model(model,inputs[train], targets[train], cross_validation=True)\n",
        " \n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "\n",
        "    print(f\"\"\"Score for fold {fold_no}:\n",
        "     {model.metrics_names[0]} of {scores[0]}; \n",
        "     {model.metrics_names[1]} of {scores[1]*100}% ;\n",
        "     {model.metrics_names[2]} of {scores[2]*100}% ;\n",
        "     {model.metrics_names[3]} of {scores[3]*100}% ;\n",
        "     {model.metrics_names[4]} of {scores[4]*100}% ;\n",
        "     \"\"\")\n",
        "    \n",
        "    loss_per_fold.append(scores[0])\n",
        "    acc_per_fold.append(scores[1])\n",
        "    precision_per_fold.append(scores[2])\n",
        "    recall_per_fold.append(scores[3])\n",
        "    f1_per_fold.append(scores[4])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "  # == Provide average scores ==\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f\"\"\"> Fold {i+1} - \n",
        "    Loss: {loss_per_fold[i]} - \n",
        "    Accuracy: {acc_per_fold[i]}% - \n",
        "    Precesion: {precision_per_fold[i]}% - \n",
        "    Recall: {recall_per_fold[i]}% - \n",
        "    F1: {f1_per_fold[i]}%\n",
        "    \"\"\")\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Precision: {np.mean(precision_per_fold)}')\n",
        "  print(f'> Recall: {np.mean(recall_per_fold)}')\n",
        "  print(f'> F1: {np.mean(f1_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CXqtIDR4jS"
      },
      "source": [
        "# Plot Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvl487sr8seD"
      },
      "source": [
        "def Plot_graphs(metric,val_metric,metric_name):\n",
        "\n",
        "  epochs=range(len(metric)) # Get number of epochs\n",
        "\n",
        "  if metric_name == \"accuracy\":\n",
        "    #------------------------------------------------\n",
        "    # Plot training and validation accuracy per epoch\n",
        "    #------------------------------------------------\n",
        "    plt.plot(epochs, metric, 'r')\n",
        "    plt.plot(epochs, val_metric, 'b')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "  elif metric_name == \"loss\" :\n",
        "    #------------------------------------------------\n",
        "    # Plot training and validation loss per epoch\n",
        "    #------------------------------------------------\n",
        "    plt.plot(epochs, metric, 'r')\n",
        "    plt.plot(epochs, val_metric, 'b')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "  elif metric_name == \"f1\" :\n",
        "    #------------------------------------------------\n",
        "    # Plot training and validation loss per epoch\n",
        "    #------------------------------------------------\n",
        "    plt.plot(epochs, metric, 'r')\n",
        "    plt.plot(epochs, val_metric, 'b')\n",
        "    plt.title('Training and validation F1')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"F1\")\n",
        "    plt.legend([\"F1\", \"Validation F1\"])\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "\n",
        "  # Expected Output\n",
        "  # A chart where the validation loss does not increase sharply!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RS6GyZ8-mk7"
      },
      "source": [
        "# Main Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN_uGz3CZMCh"
      },
      "source": [
        "## Set Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85wsS8Mn8oeI"
      },
      "source": [
        "# EMBEDDING_MATRIX = generate_embedding_metrix()\n",
        "EMBEDDING_MATRIX = load_word_embedding_atrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-x5t7AF_DGO"
      },
      "source": [
        "## Build and Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuEifQn3Jc98"
      },
      "source": [
        "def build_model() :\n",
        "  model = None\n",
        "\n",
        "  if (model_type == \"RNN\" or model_type == \"GRU\" or model_type == \"LSTM\"):\n",
        "    # configure layer\n",
        "    layer = None\n",
        "    if (model_type == \"RNN\"):\n",
        "      layer = RNN\n",
        "    elif (model_type == \"GRU\"):\n",
        "      layer = GRU\n",
        "    elif (model_type == \"LSTM\"):\n",
        "      layer = LSTM\n",
        "      \n",
        "    \n",
        "    # configure architecture\n",
        "    if (stack_modeles == \"2\"):\n",
        "      model = stacked_RNN_model_2(layer,MAX_LEN, HIDDEN_DIMS, L2_REG, DROPOUT_VALUE_1, DROPOUT_VALUE_2)\n",
        "    elif (stack_modeles == \"3\"):\n",
        "      model = stacked_RNN_model_3(layer,MAX_LEN, HIDDEN_DIMS, L2_REG, DROPOUT_VALUE_1, DROPOUT_VALUE_2)\n",
        "    elif (apply_CNN):\n",
        "      model = CNN_RNN_model(layer,MAX_LEN, HIDDEN_DIMS, L2_REG, DROPOUT_VALUE_1, DROPOUT_VALUE_2)\n",
        "    else :\n",
        "      model = RNN_model(layer,MAX_LEN, HIDDEN_DIMS, L2_REG, DROPOUT_VALUE_1, DROPOUT_VALUE_2)\n",
        "\n",
        "  elif (model_type == \"BiLSTM\" ):\n",
        "\n",
        "    # configure architecture\n",
        "    if (stack_modeles == \"2\"):\n",
        "      model = stacked_BiLSTM_model_2(MAX_LEN, DROPOUT_VALUE_1)\n",
        "    elif (stack_modeles == \"3\"):\n",
        "      model = stacked_BiLSTM_model_3(MAX_LEN, DROPOUT_VALUE_1)\n",
        "    elif (apply_CNN):\n",
        "      model = CNN_BiLSTM_model(MAX_LEN)\n",
        "    else :\n",
        "      model = BiLSTM_model(MAX_LEN, DROPOUT_VALUE_1)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d46ja9NetIpP"
      },
      "source": [
        "## Train and Test Model (Holdout Method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB39v3N61RCY"
      },
      "source": [
        "MAX_FEATURES = EMBEDDING_MATRIX.shape[0] #vocab_size\n",
        "VERBOSITY = 1\n",
        "VALIDATION_SPLIT = 0.1\n",
        "NB_EPOCHS = 4\n",
        "FOLDS = 10\n",
        "\n",
        "BATCH_SIZE = 64 # 64, 128\n",
        "NB_FILTERS = 200\n",
        "FILTER_LENGTH = 4 # test with 2,3,4,5\n",
        "HIDDEN_DIMS = NB_FILTERS * 2\n",
        "MAX_LEN = 215 #test with other values(only this value work for now)\n",
        "DROPOUT_VALUE_1 = 0.5 #0.8 #0.3\n",
        "DROPOUT_VALUE_2 = 0.1\n",
        "L2_REG= 0.01\n",
        "\n",
        "RNN = GRU\n",
        "\n",
        "rnn_output_size = 300 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "rV8W-Nthbfh5",
        "outputId": "8ea9a192-c3cf-4d86-b4a4-629f28434665"
      },
      "source": [
        "model = build_model()\n",
        "# model.load_weights(model_save_path)\n",
        "plot_model(model,to_file=\"./model.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G61FNXmM_QSL"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye7IkwWamR2c",
        "outputId": "615f5000-6677-4798-cec9-80977c1b02ef"
      },
      "source": [
        "# trained_model = Train_Model_old(model,X_train, X_test, y_train, y_test)\n",
        "# model.load_weights(model_save_path)\n",
        "trained_model, his = Train_Model(model,X_train, y_train, cross_validation = False)\n",
        "\n",
        "accuracy = his.history['accuracy']\n",
        "val_accuracy = his.history['val_accuracy']\n",
        "loss = his.history['loss']\n",
        "val_loss = his.history['val_loss']\n",
        "f1 = his.history['f1']\n",
        "val_f1 = his.history['f1']\n",
        "\n",
        "Plot_graphs(accuracy,val_accuracy, \"accuracy\")\n",
        "Plot_graphs(loss,val_loss, \"loss\")\n",
        "Plot_graphs(f1,val_f1, \"f1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training and Testing...\n",
            "(343701, 215) (343701, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 309330 samples, validate on 34371 samples\n",
            "Epoch 1/4\n",
            " 53632/309330 [====>.........................] - ETA: 11:54:26 - loss: 0.7030 - accuracy: 0.8310 - precision: 0.8139 - recall: 0.8139 - f1: 0.8310"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-RSSqI7BDqE"
      },
      "source": [
        "### Restart runtime and import Relibraries\n",
        "There is a bug, if run time isn't restart after this point, It's going to malfunction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnfxE-LmAWmK"
      },
      "source": [
        "# # os.kill(os.getpid(), 9)\n",
        "\n",
        "# exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxp9ViDsA2bb"
      },
      "source": [
        "# from keras.models import Sequential,Model,load_model\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\n",
        "\n",
        "# experiment_no = 100\n",
        "# model_name = \"RNN\"\n",
        "# experiment_name = folder_path + \"Sentiment Analysis/CNN RNN/experiments/\" + model_name +str(experiment_no)+\"_\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(context)\n",
        "\n",
        "# model_save_path = folder_path + \"Sentiment Analysis/CNN RNN/saved_models/weights_best_\"+model_name+\"_\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(experiment_no)+\".hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VdzOT3zsB9m"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMtXKRpRYBx2"
      },
      "source": [
        "#### Load Weights to Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl7JuOSe3tBl"
      },
      "source": [
        "# model_save_path = folder_path + \"Sentiment Analysis/CNN RNN/saved_models/111_weights_best_stacked_LSTM_3_fasttext_111.hdf5\"\n",
        "# model.load_weights(model_save_path)\n",
        "loaded_model  = load_model(model_save_path,custom_objects={\"f1\": f1}, compile=True)\n",
        "print(\"loaded \" + model.name)\n",
        "\n",
        "_, train_acc,train_f1 = loaded_model.evaluate(X_train, y_train, verbose=1)\n",
        "_, test_acc,test_f1= loaded_model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Train_acc: %.3f, Test_acc: %.3f, Train_f1: %.3f,  Test_f1: %.3f' % (train_acc, test_acc,train_f1,test_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtZBU5XNZaMi"
      },
      "source": [
        "#### Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmA4iDmR2czB"
      },
      "source": [
        "predictions = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "labels = np.argmax(y_test, axis=1)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(labels,predictions )\n",
        "\n",
        "# classification_report\n",
        "report = classification_report(labels, predictions, digits=4,output_dict=True)\n",
        "report_print = classification_report(labels, predictions, digits=4)\n",
        "print(report_print)\n",
        "\n",
        "# report_df = pd.DataFrame(report).transpose()\n",
        "# report_df.to_csv(experiment_name+\".csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5QjsfZxq4fq"
      },
      "source": [
        "# DataTagged_Original = pd.read_csv(all_data_path)\n",
        "DataTagged_Original = pd.concat([lankadeepa_data,gossipLanka_data], ignore_index=True)\n",
        "train_data_original, test_data_original = train_test_split(DataTagged_Original, test_size=0.1, random_state=0)\n",
        "\n",
        "predictions_series = pd.Series(predictions)\n",
        "predictions_1 = pd.get_dummies(predictions_series).idxmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT-ccXWZRdak"
      },
      "source": [
        "data_frame = pd.DataFrame({'comment': test_data_original['comment'], 'Labels': test_data_original['label'], 'Predictions': np.array(predictions_1)})\n",
        "\n",
        "def add_two(value):\n",
        "  return value+2\n",
        "data_frame[\"Predictions\"] = data_frame[\"Predictions\"].apply(add_two)\n",
        "\n",
        "prediction_save_name  = folder_path + \"Sentiment Analysis/CNN RNN/LSTM_S3_predictions_with_labels_3.csv\"\n",
        "data_frame.to_csv(prediction_save_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLkfB_XXPS3O"
      },
      "source": [
        "### Print confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdCcVDhPPN_m"
      },
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJwG_4FPQ2f"
      },
      "source": [
        "plot_confusion_matrix(cm, [0,1,2,3],normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-x34NEZtU5C"
      },
      "source": [
        "## Train and Test Model (Cross Validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iZDvr80VxPN"
      },
      "source": [
        "# Do_Cross_Validation(model,padded_docs,comment_labels)\n",
        "Do_Cross_Validation(padded_docs,comment_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR7WojLAszo7"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEjuD0hzohUv"
      },
      "source": [
        "def tune_hyperparameters(model_build_fn):\n",
        "  # fix random seed for reproducibility\n",
        "  seed = 7\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  model = KerasClassifier(build_fn=model_build_fn, maxlen=MAX_LEN, hidden_dims=HIDDEN_DIMS, l2_reg= L2_REG, verbose=VERBOSITY)\n",
        "\n",
        "  # optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "  maxlen_list  = [210]\n",
        "  hidden_dims_list = [300, 400, 500, 600]\n",
        "  l2_reg_list = [0.01, 0.02]\n",
        "  drop_out_value_list = [0.5, 0.8]\n",
        "  # tune for kernal size 2,3,4,5\n",
        "\n",
        "\n",
        "  param_grid = dict(maxlen=maxlen_list, hidden_dims = hidden_dims_list, l2_reg= l2_reg_list, drop_out_value = drop_out_value_list )\n",
        "  grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=FOLDS, verbose = 10 )\n",
        "  grid_result = grid.fit(padded_docs, comment_labels)\n",
        "\n",
        "  # summarize results\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHYpTsTDtFIr"
      },
      "source": [
        "# tune_hyperparameters(build_BiLSTM_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}